{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "\n",
    "from settings import EXPERIMENTS_DIR\n",
    "from experiment import Experiment\n",
    "from utils import to_device, load_weights, load_embeddings, create_embeddings_matrix\n",
    "from vocab import Vocab\n",
    "from train import create_model\n",
    "from preprocess import load_dataset, create_dataset_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_id = 'train.6yk107k2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = Experiment.load(EXPERIMENTS_DIR, exp_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainConfig(model_class=<class 'models.Seq2SeqMeaningStyle'>, preprocess_exp_id='preprocess.nbsquesc', embedding_size=300, hidden_size=256, dropout=0.2, scheduled_sampling_ratio=0.5, pretrained_embeddings=True, trainable_embeddings=False, meaning_size=128, style_size=128, lr=0.001, weight_decay=1e-07, grad_clipping=5, D_num_iterations=10, D_loss_multiplier=1, P_loss_multiplier=10, P_bow_loss_multiplier=1, use_discriminator=True, use_predictor=False, use_predictor_bow=True, use_motivator=True, use_gauss=False, num_epochs=500, batch_size=1024, best_loss='loss')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 453655, val: 10000, test: 10000\n",
      "Vocab: 9419, style vocab: 2\n",
      "W_emb: (9419, 300)\n"
     ]
    }
   ],
   "source": [
    "preprocess_exp = Experiment.load(EXPERIMENTS_DIR, exp.config.preprocess_exp_id)\n",
    "dataset_train, dataset_val, dataset_test, vocab, style_vocab, W_emb = load_dataset(preprocess_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_reader = create_dataset_reader(preprocess_exp.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(exp.config, vocab, style_vocab, dataset_train.max_len, W_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_weights(model, exp.experiment_dir.joinpath('best.th'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inputs(instances):\n",
    "    if not isinstance(instances, list):\n",
    "        instances = [instances,]\n",
    "        \n",
    "    if not isinstance(instances[0], dict):\n",
    "        sentences = [\n",
    "            dataset_reader.preprocess_sentence(dataset_reader.spacy( dataset_reader.clean_sentence(sent)))\n",
    "            for sent in instances\n",
    "        ]\n",
    "        \n",
    "        style = list(style_vocab.token2id.keys())[0]\n",
    "        instances = [\n",
    "            {\n",
    "                'sentence': sent,\n",
    "                'style': style,\n",
    "            }\n",
    "            for sent in sentences\n",
    "        ]\n",
    "        \n",
    "        for inst in instances:\n",
    "            inst_encoded = dataset_train.encode_instance(inst)\n",
    "            inst.update(inst_encoded)            \n",
    "    \n",
    "    \n",
    "    instances = [\n",
    "        {\n",
    "            'sentence': inst['sentence_enc'],\n",
    "            'style': inst['style_enc'],\n",
    "        } \n",
    "        for inst in instances\n",
    "    ]\n",
    "    \n",
    "    instances = default_collate(instances)\n",
    "    instances = to_device(instances)      \n",
    "    \n",
    "    return instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(outputs):\n",
    "    predicted_indices = outputs[\"predictions\"]\n",
    "    end_idx = vocab[Vocab.END_TOKEN]\n",
    "    \n",
    "    if not isinstance(predicted_indices, np.ndarray):\n",
    "        predicted_indices = predicted_indices.detach().cpu().numpy()\n",
    "\n",
    "    all_predicted_tokens = []\n",
    "    for indices in predicted_indices:\n",
    "        indices = list(indices)\n",
    "\n",
    "        # Collect indices till the first end_symbol\n",
    "        if end_idx in indices:\n",
    "            indices = indices[:indices.index(end_idx)]\n",
    "\n",
    "        predicted_tokens = [vocab.id2token[x] for x in indices]\n",
    "        all_predicted_tokens.append(predicted_tokens)\n",
    "        \n",
    "    return all_predicted_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': ['they', 'are', 'really', 'good', 'people', '.'],\n",
       " 'style': 'positive',\n",
       " 'sentence_enc': array([136,  55,  29, 380, 368,   8,   2,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0]),\n",
       " 'style_enc': 1,\n",
       " 'meaning_embedding': array([-9.50000435e-03, -1.41124994e-01, -4.41750027e-02,  1.90999992e-02,\n",
       "        -1.24025002e-01, -1.08074993e-01, -1.93949997e-01,  8.38750005e-02,\n",
       "         1.44350007e-01, -2.35500000e-02, -4.74999845e-03,  1.44600004e-01,\n",
       "        -3.93499993e-02, -1.70499980e-02, -4.63999994e-02,  3.37999985e-02,\n",
       "        -4.23750058e-02, -4.57499996e-02, -7.32000023e-02,  6.25500008e-02,\n",
       "        -4.92749996e-02, -7.62749985e-02,  8.68999958e-02, -4.80250008e-02,\n",
       "        -1.40974998e-01, -5.85000031e-03,  5.96000031e-02,  1.64500009e-02,\n",
       "        -7.30000250e-03,  1.92149997e-01, -8.38999972e-02,  8.42499826e-03,\n",
       "         1.69999897e-03, -2.49949992e-01,  1.04975000e-01, -9.66750011e-02,\n",
       "         6.30000141e-03, -4.97250035e-02, -1.64999999e-02,  3.13174993e-01,\n",
       "         4.19999938e-03,  8.30999985e-02, -1.42500000e-02, -6.00249991e-02,\n",
       "         2.70499997e-02, -3.62749994e-02,  2.31749974e-02, -3.90250012e-02,\n",
       "         5.16000018e-02, -1.26999989e-02, -8.78999978e-02, -1.18299998e-01,\n",
       "         2.31450006e-01,  7.95999989e-02,  6.06500022e-02,  2.09250003e-02,\n",
       "        -8.74500051e-02,  2.01100007e-01, -3.54500003e-02, -1.06449999e-01,\n",
       "        -1.36549994e-01,  3.45749967e-02, -5.25249988e-02, -3.13000008e-02,\n",
       "         2.04250012e-02, -9.08000022e-02, -5.28750010e-02,  1.02100000e-01,\n",
       "         8.20000097e-03, -5.78000024e-02, -3.63749973e-02, -8.07499886e-03,\n",
       "        -3.57250012e-02,  3.09850007e-01, -2.72249989e-02, -1.09124996e-01,\n",
       "        -6.91325009e-01, -5.70000336e-03,  2.06750005e-01,  4.18999977e-02,\n",
       "         3.53224993e-01,  6.34999946e-03, -7.05000013e-02,  4.01500016e-02,\n",
       "        -7.67000020e-02,  2.41249986e-02,  1.11625001e-01, -6.37999997e-02,\n",
       "        -6.06999993e-02, -8.68249983e-02, -4.70499992e-02,  1.53074995e-01,\n",
       "         6.78749979e-02,  2.48249993e-02,  1.81749985e-02,  3.05000134e-03,\n",
       "         1.08500011e-02, -3.28999944e-02, -7.59750009e-02, -5.75250015e-02,\n",
       "        -4.94499989e-02, -5.12500014e-03,  9.09000039e-02,  1.19500011e-02,\n",
       "         5.73000014e-02,  2.05999985e-02,  4.28750031e-02, -6.95749968e-02,\n",
       "        -1.24674998e-01,  1.58749998e-01,  2.00249981e-02, -3.17750014e-02,\n",
       "         4.99999616e-04,  1.09000001e-02, -4.81575012e-01, -3.30749974e-02,\n",
       "         2.55999994e-02,  3.17500010e-02, -7.08749965e-02, -4.50500026e-02,\n",
       "        -1.21975005e-01,  3.57500091e-03, -3.64250019e-02, -9.58499983e-02,\n",
       "        -3.72500066e-03, -2.79749986e-02,  9.53999981e-02,  1.69500038e-02,\n",
       "         1.17250085e-02, -3.11249997e-02,  4.86500002e-02, -1.03949994e-01,\n",
       "        -2.78750025e-02, -1.60249993e-02,  6.50750026e-02, -1.01150006e-01,\n",
       "        -1.86149999e-01,  5.03000021e-02, -3.20999995e-02, -2.73474991e-01,\n",
       "        -4.65499982e-02, -6.22749999e-02,  2.29749996e-02,  2.12050006e-01,\n",
       "        -5.11249974e-02, -9.27000046e-02,  4.23750058e-02,  6.45250008e-02,\n",
       "         1.26374990e-01, -1.64149985e-01, -2.49249991e-02, -8.03250000e-02,\n",
       "        -1.06999995e-02, -4.28249985e-02,  2.96249986e-02, -2.39999965e-02,\n",
       "        -9.71250087e-02,  8.73750001e-02,  5.79250008e-02,  5.74999489e-04,\n",
       "         5.35175025e-01, -7.71749914e-02, -1.00850001e-01,  4.33750041e-02,\n",
       "         1.08849995e-01, -7.28500038e-02,  5.64000010e-02, -1.11350000e-01,\n",
       "         6.18750043e-02, -8.42999965e-02, -6.72750026e-02,  6.84750006e-02,\n",
       "         3.67249995e-02,  1.57750007e-02,  8.48999992e-02, -5.85249960e-02,\n",
       "        -2.59249993e-02,  6.82500005e-02,  5.44250011e-02, -6.51250035e-02,\n",
       "        -2.16500014e-02,  1.54000008e-02,  7.95499980e-02, -5.36000021e-02,\n",
       "        -4.38250005e-02,  1.64999999e-02,  1.83299989e-01, -6.38249964e-02,\n",
       "         1.11924998e-01,  2.27250047e-02, -2.65999995e-02,  2.69999988e-02,\n",
       "        -5.48000000e-02, -3.92500013e-02,  4.19999994e-02,  3.24000008e-02,\n",
       "        -7.39999861e-03, -2.73750015e-02, -8.79749954e-02,  8.22499953e-03,\n",
       "        -1.10075004e-01, -1.00750010e-02,  8.41750056e-02,  1.09749986e-02,\n",
       "        -8.66999999e-02, -2.78500021e-02, -6.36999980e-02, -2.92750020e-02,\n",
       "        -3.62499990e-02,  1.96999982e-02,  1.30400002e-01,  5.18525004e-01,\n",
       "         8.08999985e-02,  1.66000016e-02,  5.30750006e-02, -6.80750012e-02,\n",
       "         6.48500025e-02, -6.74000010e-02,  5.49249984e-02,  4.38250005e-02,\n",
       "         3.27749997e-02,  4.98250015e-02,  2.56250016e-02, -8.20000097e-03,\n",
       "        -7.67499954e-02,  9.43500027e-02, -3.59999947e-03,  7.09249973e-02,\n",
       "        -4.70000021e-02,  4.08750027e-02,  5.25500029e-02, -1.31475002e-01,\n",
       "         9.33500081e-02,  1.40500013e-02, -7.06750005e-02, -1.32124990e-01,\n",
       "         4.98500019e-02, -8.73249993e-02, -2.72250008e-02, -7.96250030e-02,\n",
       "         8.45249966e-02, -1.01824999e-01, -3.20500024e-02,  3.16499993e-02,\n",
       "        -2.29200006e-01,  4.89749983e-02, -7.88999945e-02,  2.99750008e-02,\n",
       "        -1.60750020e-02,  2.74000000e-02,  1.01374999e-01, -3.35999988e-02,\n",
       "         2.85250004e-02,  1.77499987e-02, -1.79250017e-02,  3.39250006e-02,\n",
       "        -3.82750034e-02,  1.81999989e-02,  4.29999977e-02,  4.84750010e-02,\n",
       "         8.57500080e-03, -5.69999963e-03,  1.40200004e-01,  2.22500134e-03,\n",
       "         8.07500035e-02,  3.22750024e-02,  2.87250020e-02, -1.92499999e-02,\n",
       "        -3.01749967e-02,  1.60750002e-02, -3.68499979e-02,  8.26999992e-02,\n",
       "        -5.28750010e-02,  4.53500003e-02,  8.55249986e-02,  1.35499984e-02,\n",
       "         4.51250002e-02,  9.10000131e-03, -6.27250001e-02, -7.33750015e-02,\n",
       "         1.15750022e-02, -1.70474991e-01, -8.25000033e-02, -1.21550001e-01,\n",
       "        -6.75249994e-02,  1.21000009e-02, -5.99499978e-02,  5.11500016e-02,\n",
       "        -5.54499999e-02, -5.56249991e-02,  2.41000019e-02,  3.68250012e-02,\n",
       "         1.75499991e-02, -8.45000893e-03, -5.16000018e-02, -1.34399995e-01,\n",
       "        -2.63999980e-02, -6.12249970e-02, -1.67999975e-02, -3.86749990e-02],\n",
       "       dtype=float32)}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_val.instances[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence =  ' '.join(dataset_val.instances[1]['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'they are really good people .'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': tensor([[136,  55,  29, 380, 368,   8,   2,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0]], device='cuda:0'),\n",
       " 'style': tensor([0], device='cuda:0')}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = create_inputs(sentence)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = get_sentences(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'they are really good people .'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(sentences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Swap style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_styles = list(style_vocab.token2id.keys()) #['negative', 'positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative', 'positive']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences0 = [s for s in dataset_val.instances if s['style'] == possible_styles[0]]\n",
    "sentences1 = [s for s in dataset_val.instances if s['style'] == possible_styles[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126 the gyro meat was greasy and dried out at the same time .\n",
      "1913 after over number years with this institution i believe we deserve more !\n",
      "2372 that cost $ number .\n",
      "1410 this place however , does not !\n",
      "737 being from louisiana , i am a huge smoothie king fan .\n"
     ]
    }
   ],
   "source": [
    "for i in np.random.choice(np.arange(len(sentences0)), 5):\n",
    "    print(i, ' '.join(sentences0[i]['sentence']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664 everything about this place was clean and professional .\n",
      "2455 everything we have had here has been good !\n",
      "1393 bonus is a friendly cat hanging around the patio .\n",
      "4442 their food is what i crave .\n",
      "1364 good place for lunch if you are looking for a burger .\n"
     ]
    }
   ],
   "source": [
    "for i in np.random.choice(np.arange(len(sentences1)), 5):\n",
    "    print(i, ' '.join(sentences1[i]['sentence']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Swap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "target0 = 2346 # np.random.choice(np.arange(len(sentences0)))\n",
    "target1 = 1364 # np.random.choice(np.arange(len(sentences0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not a place for adults .\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(sentences0[target0]['sentence']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good place for lunch if you are looking for a burger .\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(sentences1[target1]['sentence']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': tensor([[ 32,  24,  83,  52, 762,   8,   2,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0],\n",
       "         [380,  83,  52, 940, 199,  56,  55, 671,  52,  24, 244,   8,   2,   0,\n",
       "            0,   0,   0,   0,   0,   0]], device='cuda:0'),\n",
       " 'style': tensor([0, 1], device='cuda:0')}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = create_inputs([\n",
    "    sentences0[target0],\n",
    "    sentences1[target1],\n",
    "])\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_hidden = model.encode(inputs)\n",
    "style_z_hidden = z_hidden['style_hidden'].clone()\n",
    "meaning_z_hidden = z_hidden['meaning_hidden'].clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_hidden['style_hidden'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_hidden['meaning_hidden'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_decoded = model.decode(z_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_sentences = get_sentences(original_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not a place for adults .\n",
      "good place for lunch if you are looking for a burger .\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(original_sentences[0]))\n",
    "print(' '.join(original_sentences[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z_hidden_swapped = {\n",
    "#     'meaning_hidden': torch.stack([\n",
    "#         meaning_z_hidden[1].clone(),\n",
    "#         meaning_z_hidden[0].clone(),        \n",
    "#     ], dim=0),\n",
    "#     'style_hidden': torch.stack([\n",
    "#         style_z_hidden[0].clone(),\n",
    "#         style_z_hidden[1].clone(),        \n",
    "#     ], dim=0),\n",
    "#     'decoder_hidden': torch.stack([\n",
    "#         z_hidden['decoder_hidden'][0].clone(),\n",
    "#         z_hidden['decoder_hidden'][1].clone(),        \n",
    "#     ], dim=0)\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'torch' from '/home/oleg/anaconda3/lib/python3.7/site-packages/torch/__init__.py'>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand_like(meaning_z_hidden[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_hidden_swapped = {\n",
    "    'meaning_hidden': torch.stack([\n",
    "        meaning_z_hidden[1].clone(),\n",
    "        meaning_z_hidden[0].clone(),        \n",
    "    ], dim=0),\n",
    "    'style_hidden': torch.stack([\n",
    "        style_z_hidden[0].clone() * 4,\n",
    "        style_z_hidden[1].clone() * 4,        \n",
    "    ], dim=0),\n",
    "    'decoder_hidden': torch.stack([\n",
    "        z_hidden['decoder_hidden'][0].clone(),\n",
    "        z_hidden['decoder_hidden'][1].clone(),        \n",
    "    ], dim=0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "swaped_decoded = model.decode(z_hidden_swapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "swaped_sentences = get_sentences(swaped_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not a place for adults .\n",
      "good place for lunch if you are looking for a burger .\n",
      "\n",
      "not provide place place craft .\n",
      "kind recommend for lunch if you are prepared for a burger .\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(original_sentences[0]))\n",
    "print(' '.join(original_sentences[1]))\n",
    "print()\n",
    "print(' '.join(swaped_sentences[0]))\n",
    "print(' '.join(swaped_sentences[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not a place for adults .\n",
      "good place for lunch if you are looking for a burger .\n",
      "\n",
      "not a place for adults .\n",
      "good place for lunch if you are looking for a burger .\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(original_sentences[0]))\n",
    "print(' '.join(original_sentences[1]))\n",
    "print()\n",
    "print(' '.join(swaped_sentences[0]))\n",
    "print(' '.join(swaped_sentences[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
